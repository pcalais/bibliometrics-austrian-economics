{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEscreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "tei_path = \"../data/interim/test_tei\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_year(citation):\n",
    "    match = re.search(r'\\b(\\d{4})\\b', citation)\n",
    "    return (int(match.group(1)), None) if match else (None, None)\n",
    "\n",
    "\n",
    "def extract_year_and_page(citation):\n",
    "\n",
    "    if citation is None:\n",
    "        return (None, None)\n",
    "\n",
    "    # Use a regular expression to extract the year and page\n",
    "    match = re.search(\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?)[:\\s,]*pp?\\.\\s*(\\d+)(?:-\\d+)?|\"  # Match for \"pp.\" or \"p.\" with year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?):\\s*(\\d+)|\"                     # Match for \":\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*(\\d+)-\\d+|\"                # Match for page range without \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*(\\d+)(?:-\\d+)?|\"           # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" without explicit parentheses\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?)\\s*:\\s*(\\d+)|\"                  # Match for \": Page\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*)pp?\\.\\s*(\\d+)|\"                                # Match for \"pp.\" without year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*chap\\.\\s*(\\d+)\",           # Match for \"chap.\" format\n",
    "        citation\n",
    "    )\n",
    "    if match:\n",
    "        if match.group(1):  # Match for \"pp.\" or \"p.\" with year\n",
    "            year = match.group(1)\n",
    "            page = int(match.group(2))\n",
    "        elif match.group(3):  # Match for \":\" format\n",
    "            year = match.group(3)\n",
    "            page = int(match.group(4))\n",
    "        elif match.group(5):  # Match for single \"p.\" with year\n",
    "            year = match.group(5)\n",
    "            page = int(match.group(6))\n",
    "        elif match.group(7):  # Match for range without \"pp.\" or \"p.\"\n",
    "            year = match.group(7)\n",
    "            page = int(match.group(8))\n",
    "        elif match.group(9):  # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "            year = match.group(9)\n",
    "            page = int(match.group(10))\n",
    "        elif match.group(11):  # Match for \"p.\" without year and page\n",
    "            year = match.group(11)\n",
    "            page = int(match.group(12))\n",
    "        elif match.group(13):  # Match for \": Page\" format\n",
    "            year = match.group(13)\n",
    "            page = int(match.group(14))\n",
    "        elif match.group(15):  # Match for \"pp.\" without year\n",
    "            year = None\n",
    "            page = int(match.group(15))\n",
    "        elif match.group(16):  # Match for \"chap.\" format\n",
    "            year = match.group(16)\n",
    "            page = int(match.group(17))\n",
    "        \n",
    "        # Strip the letter suffix from the year before returning (if present)\n",
    "        if year:\n",
    "            year = int(re.match(r'\\d{4}', year).group())\n",
    "\n",
    "        return year, page\n",
    "    else:\n",
    "        return extract_year(citation)  # Return None if the format doesn't match\n",
    "    \n",
    "\n",
    "# Test the function\n",
    "assert extract_year_and_page(\"Mises (1949, p.258)\") == (1949, 258)\n",
    "assert extract_year_and_page(\"(Mises, 1996, pp. 538-86)\") == (1996, 538)\n",
    "assert extract_year_and_page(\"(von Mises, 1963, p.254)\") == (1963, 254)\n",
    "assert extract_year_and_page(\"(Mises, 1920, 121-122)\") == (1920, 121)\n",
    "assert extract_year_and_page(\"(Mises 1949, 236-237)\") == (1949, 236)\n",
    "assert extract_year_and_page(\"(Mises 1920, 109)\") == (1920, 109)\n",
    "assert extract_year_and_page(\"(Mises 1920, p.162)\") == (1920, 162)\n",
    "assert extract_year_and_page(\"(von Mises, 1949: 351)\") == (1949, 351)\n",
    "assert extract_year_and_page(\"(Mises 1966: 493)\") == (1966, 493)\n",
    "assert extract_year_and_page(\"(von Mises 1998, p. 270)\") == (1998, 270)\n",
    "assert extract_year_and_page(\"Mises 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"Mises 1985b, p. 236\") == (1985, 236)\n",
    "assert extract_year_and_page(\"Mises 1957b, 372\") == (1957, 372)\n",
    "assert extract_year_and_page(\"Mises, pp. 105-6;\") == (None, 105)\n",
    "assert extract_year_and_page(\"(Mises, 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949, pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949 , pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(C Berg 2022)\") == (2022, None)\n",
    "assert extract_year_and_page(\"Hayek (1976:71)\") == (1976, 71)\n",
    "assert extract_year_and_page(\"According to Mises ([1949] 1998: 116)\") == (1998, 116)\n",
    "\n",
    "# (Mises 1998, 419–21, 545–47)\n",
    "\n",
    "assert extract_year_and_page(None) == (None, None)\n",
    "assert extract_year_and_page(\"[and]\") == (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_author(ref):\n",
    "    if ref is None:\n",
    "        return None\n",
    "\n",
    "    match = re.search(\n",
    "        r\"([A-Za-z][A-Za-z\\s\\.']+?)\"\n",
    "        r\"(?:\\s+(?:and|And|&)\\s+[A-Za-z][A-Za-z\\s\\.']+)?\"\n",
    "        r\"(?=\\s\\d{4}|\\s\\[|\\s\\(|,|:|\\))\",\n",
    "        ref\n",
    "    )\n",
    "\n",
    "    if match:\n",
    "        name = match.group(1).strip()\n",
    "\n",
    "        # Remove possessive 's\n",
    "        name = re.sub(r\"'s$\", \"\", name)\n",
    "\n",
    "        lowercase_particles = {\"de\", \"der\", \"von\"}\n",
    "        ignore_words = {\"et\", \"al.\"}\n",
    "\n",
    "        def normalize(word):\n",
    "            w = word.lower()\n",
    "            if w in lowercase_particles:\n",
    "                return w\n",
    "            if w in ignore_words:\n",
    "                return word\n",
    "            if w.startswith(\"mc\") and len(w) > 2:\n",
    "                return \"Mc\" + w[2].upper() + w[3:]\n",
    "            return word.capitalize()\n",
    "\n",
    "        temp = \" \".join(normalize(word) for word in name.split())\n",
    "\n",
    "        temp = (\n",
    "            temp.replace(\"von Mises\", \"Mises\")\n",
    "                .replace(\"Von Mises\", \"Mises\")\n",
    "                .replace(\"L V Mises\", \"Mises\")\n",
    "                .replace(\"L Mises\", \"Mises\")\n",
    "                .replace(\"L Von Mises\", \"Mises\")\n",
    "                .replace(\"von Hayek\", \"Hayek\")\n",
    "                .replace(\"Von Hayek\", \"Hayek\")\n",
    "                .replace(\"F A Hayek\", \"Hayek\")\n",
    "                .replace(\"K Marx\", \"Marx\")\n",
    "                .replace(\" et al.\", \"\")\n",
    "        )\n",
    "\n",
    "        return temp.strip()\n",
    "\n",
    "    match_single_word = re.search(\n",
    "        r\"([A-Za-z]+(?:'s)?)(?=\\s\\d{4}|\\s\\(|:|\\))\",\n",
    "        ref\n",
    "    )\n",
    "\n",
    "    if match_single_word:\n",
    "        name = match_single_word.group(1).replace(\"'s\", \"\")\n",
    "        return name.capitalize()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test cases\n",
    "assert extract_author(\"Johnson, 1999;\") == \"Johnson\"             \n",
    "assert extract_author(\"Jouvenel (1961)\") == \"Jouvenel\"\n",
    "assert extract_author(\"Keen 2011\") == \"Keen\"\n",
    "assert extract_author(\"(Menger, [1981])\") == \"Menger\"\n",
    "assert extract_author(\"von Mises (1949)\") == \"Mises\"\n",
    "assert extract_author(\"Von Hayek (1949)\") == \"Hayek\"\n",
    "assert extract_author(\"de Broglie (1924)\") == \"de Broglie\"\n",
    "assert extract_author(\"Allen 2005)\") == \"Allen\"\n",
    "assert extract_author(\"Folta's (1998)\") == \"Folta\"\n",
    "assert extract_author(\"Boettke et al. (1998)\") == \"Boettke\"\n",
    "assert extract_author(\"Floss and Klein (1998)\") == \"Floss\"\n",
    "assert extract_author(\"Floss And Klein (1998)\") == \"Floss\"\n",
    "assert extract_author(\"(Von Mises 1949 )\") == \"Mises\"\n",
    "assert extract_author(\"(L V Mises 1949 )\") == \"Mises\" \n",
    "assert extract_author(\"(L Mises 1998 )\") == \"Mises\"\n",
    "assert extract_author(\"(L Von Mises 1998 )\") == \"Mises\"\n",
    "assert extract_author(\"Van der Waals (1873)\") == \"Van der Waals\"\n",
    "assert extract_author(\"(McGrath et al., 2004: 96)\") == \"McGrath\"\n",
    "assert extract_author(\"Shane and Venkataraman's (2000)\") == \"Shane\"\n",
    "assert extract_author(\"(Alvarez & Barney, 2007\") == \"Alvarez\"\n",
    "\n",
    "\n",
    "assert extract_author(None) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Gere código python que cria uma classe Reference que tem atributos: raw, context, sentence_seq_number, sentence_id, author, page, year. \n",
    "raw, context, e sentence_id são passados pelo construtor.\n",
    "page e year são obtidos a partir da chamada à extract_year_and_page(raw), que retorna uma tupla (year, page).\n",
    "author é obtido a partir da chamada a extract_author(raw).\n",
    "'''\n",
    "\n",
    "class Reference:\n",
    "    def __init__(self, raw, context, sentence_seq_number, sentence_id):\n",
    "        self.raw = raw\n",
    "        self.context = context\n",
    "        self.sentence_seq_number = sentence_seq_number\n",
    "        self.sentence_id = sentence_id\n",
    "\n",
    "        self.year, self.page = extract_year_and_page(raw)\n",
    "        self.author = extract_author(raw)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Reference(raw={self.raw!r}, context={self.context!r}, \"\n",
    "                f\"sentence_id={self.sentence_id!r}, year={self.year!r}, page={self.page!r})\")\n",
    "\n",
    "\n",
    "\n",
    "ref = Reference(\"(L Von Mises 1949 , pp. 393)\", \"\",  3, \"123\")\n",
    "assert ref.year == 1949\n",
    "assert ref.page == 393\n",
    "assert ref.sentence_seq_number == 3\n",
    "assert ref.author == \"Mises\"\n",
    "\n",
    "\n",
    "ref = Reference(None, None, None, None)\n",
    "assert ref.year == None\n",
    "assert ref.page == None\n",
    "assert ref.sentence_seq_number == None\n",
    "assert ref.author == None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "\n",
    "Write a function parse_tei(tei_filepath) that opens the TEI XML file and counts the number of biblStruct entries. \n",
    "Also, count the number of <s></s> entries. \n",
    "Return four values:  \n",
    "1. The paper title, available in teiHeader / fileDesc / titleStmt / title.\n",
    "2. the number of s entries\n",
    "3. the number of biblStruct entries\n",
    "4. a list of Reference objects.  \n",
    "\n",
    "Each reference object has a field raw, a field sentence_seq_number, a field sentence_id and a field context. \n",
    "\n",
    "Raw should be filled with the text inside the ref tag; context should be filled with the text on the parent <s> tag. \n",
    "sentence_seq should be filled with the sequential count of the <s> in the XML file, e.g, sentence_seq = 10 if s is the 10th sentence in the file.\n",
    "sentence_id should be filled with the value of the property \"xml:id\" from the parent <s> tag.\n",
    "\n",
    "'''\n",
    "\n",
    "from lxml import etree\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def parse_tei(tei_filepath: str) -> Tuple[str, int, int, List[Reference]]:\n",
    "    # Parse the XML\n",
    "    parser = etree.XMLParser(ns_clean=True)\n",
    "    tree = etree.parse(tei_filepath, parser)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # TEI namespace (if any)\n",
    "    nsmap = root.nsmap.copy()\n",
    "    nsmap['tei'] = nsmap.get(None, 'http://www.tei-c.org/ns/1.0')\n",
    "\n",
    "    # 1. Paper title\n",
    "    title_xpath = './/tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title'\n",
    "    title_elem = root.find(title_xpath, namespaces=nsmap)\n",
    "    title = title_elem.text.strip() if title_elem is not None and title_elem.text is not None else \"Unknown Title\"\n",
    "\n",
    "    # 2. Count number of <s> entries\n",
    "    s_xpath = './/tei:s'\n",
    "    s_elems = root.findall(s_xpath, namespaces=nsmap)\n",
    "    num_s = len(s_elems)\n",
    "\n",
    "    # 3. Count number of <biblStruct> entries\n",
    "    bibl_xpath = './/tei:biblStruct'\n",
    "    bibl_elems = root.findall(bibl_xpath, namespaces=nsmap)\n",
    "    num_bibl = len(bibl_elems)\n",
    "\n",
    "    # 4. References\n",
    "    references = []\n",
    "    for idx, s in enumerate(s_elems, start=1):\n",
    "        sentence_id = s.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "        context_text = ''.join(s.itertext()).strip()\n",
    "\n",
    "        for ref in s.findall('.//tei:ref', namespaces=nsmap):\n",
    "            ref_text = ''.join(ref.itertext()).strip()\n",
    "            references.append(Reference(\n",
    "                raw=ref_text,\n",
    "                sentence_seq_number=idx,\n",
    "                sentence_id=sentence_id,\n",
    "                context=context_text\n",
    "            ))\n",
    "\n",
    "    return title, num_s, num_bibl, references\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE 1\n",
    "\n",
    "paper_path = \"../data/interim/tei/A-Historical-Intervention-in-the-Opportunity-Wars-Forgotten-Scholarship-the-DiscoveryCreation-Disruption-and-Moving-Forward-by-Looking-Backward_2023_SAGE-Publications-Ltd.pdf.grobid.tei.xml\"\n",
    "title, sentence_count, reference_count, refs = parse_tei(paper_path) \n",
    "\n",
    "assert sentence_count == 283\n",
    "assert reference_count == 106\n",
    "assert len(refs) == 222\n",
    "assert title == \"A Historical Intervention in the \\\"Opportunity Wars\\\": Forgotten Scholarship, the Discovery/Creation Disruption, and Moving Forward by Looking Backward\"\n",
    "\n",
    "assert refs[0].sentence_id == '_paHYmXc'\n",
    "assert refs[0].sentence_seq_number == 7\n",
    "\n",
    "target = \"Besides Cole's (1959) early discussion\"\n",
    "matches = [ref for ref in refs if ref.context.startswith(target)]\n",
    "assert len(matches) == 6\n",
    "assert matches[0].sentence_seq_number == 36\n",
    "\n",
    "target = \"Furthermore, one should not neglect the wealth\"\n",
    "matches = [ref for ref in refs if ref.context.startswith(target)]\n",
    "assert len(matches) == 3\n",
    "assert matches[0].sentence_seq_number == 37\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e cria dois dataframes.\n",
    "Um pandas df chamado \"papers_df\" em que cada registro tem a coluna paper_id, que é um número sequencial, além das colunas title, filename, sentence_count, reference_count.\n",
    "Para cada arquivo, invoque parse_tei(tei_filepath), que retorna sentence_count, reference_count e refs.  \n",
    "Adicione sentence_count e reference_count no papers_df.  \n",
    "Add a try-catch loop that catches exceptions in XML Parsing.\n",
    "Ao outro df, chamado refs_df, adicione todos os refs. Um ref é um objeto Reference que tem os campos raw, context, sentence_id, sentence_seq_number e page.\n",
    "Cada campo deve ser uma coluna em refs_df.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from xml.etree.ElementTree import ParseError\n",
    "\n",
    "\n",
    "def read_tei_papers(path: str):\n",
    "    papers = []\n",
    "    refs = []\n",
    "\n",
    "    paper_id = 1\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tei_filepath = os.path.join(path, filename)\n",
    "            try:\n",
    "                title, sentence_count, reference_count, ref_list = parse_tei(tei_filepath)\n",
    "\n",
    "                # Adiciona entrada ao papers_df\n",
    "                papers.append({\n",
    "                    \"paper_id\": paper_id,\n",
    "                    \"title\": title,\n",
    "                    \"filename\": filename,\n",
    "                    \"sentence_count\": sentence_count,\n",
    "                    \"reference_count\": reference_count\n",
    "                })\n",
    "\n",
    "                # Adiciona entradas ao refs_df\n",
    "                for ref in ref_list:\n",
    "                    refs.append({\n",
    "                        \"paper_id\": paper_id,\n",
    "                        \"raw\": ref.raw,\n",
    "                        \"context\": ref.context,\n",
    "                        \"sentence_id\": ref.sentence_id,\n",
    "                        \"sentence_seq_number\": ref.sentence_seq_number,\n",
    "                        \"author\": ref.author,\n",
    "                        \"page\": ref.page,\n",
    "                        \"year\": ref.year\n",
    "                    })\n",
    "\n",
    "                paper_id += 1\n",
    "\n",
    "            except ParseError as e:\n",
    "                print(f\"Erro ao processar {filename}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro desconhecido em {filename}: {e}\")\n",
    "\n",
    "    # Cria os DataFrames\n",
    "    papers_df = pd.DataFrame(papers)\n",
    "    refs_df = pd.DataFrame(refs)\n",
    "\n",
    "    return papers_df, refs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Link</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Open Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two worlds collide: A review essay of Humanomi...</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>10.1007/s11138-022-00610-y</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Adam Smith; B12; B13; B25; B53; Behavioral eco...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MODERN AUSTRIAN ECONOMICS: Archaeology of a Re...</td>\n",
       "      <td>Modern Austrian Economics: Archaeology of a Re...</td>\n",
       "      <td>10.4324/9781003549666</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taylor and Francis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial intelligence and economic planning</td>\n",
       "      <td>AI and Society</td>\n",
       "      <td>10.1007/s00146-022-01523-x</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Artificial intelligence; Economic planning; H1...</td>\n",
       "      <td>Springer Science and Business Media Deutschlan...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"WHAT IS AN OPPORTUNITY?\": FROM THEORETICAL MY...</td>\n",
       "      <td>Academy of Management Review</td>\n",
       "      <td>10.5465/amr.2020.0335</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academy of Management</td>\n",
       "      <td>All Open Access; Green Open Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Organizational Inefficiency Adversely Affe...</td>\n",
       "      <td>Studia Universitatis Vasile Goldis Arad, Econo...</td>\n",
       "      <td>10.2478/sues-2024-0017</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>asset size; capital market; firm size; mission...</td>\n",
       "      <td>Sciendo</td>\n",
       "      <td>All Open Access; Gold Open Access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Two worlds collide: A review essay of Humanomi...   \n",
       "1  MODERN AUSTRIAN ECONOMICS: Archaeology of a Re...   \n",
       "2      Artificial intelligence and economic planning   \n",
       "3  \"WHAT IS AN OPPORTUNITY?\": FROM THEORETICAL MY...   \n",
       "4  How Organizational Inefficiency Adversely Affe...   \n",
       "\n",
       "                                        Source title  \\\n",
       "0                       Review of Austrian Economics   \n",
       "1  Modern Austrian Economics: Archaeology of a Re...   \n",
       "2                                     AI and Society   \n",
       "3                       Academy of Management Review   \n",
       "4  Studia Universitatis Vasile Goldis Arad, Econo...   \n",
       "\n",
       "                          DOI  \\\n",
       "0  10.1007/s11138-022-00610-y   \n",
       "1       10.4324/9781003549666   \n",
       "2  10.1007/s00146-022-01523-x   \n",
       "3       10.5465/amr.2020.0335   \n",
       "4      10.2478/sues-2024-0017   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "1  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "2  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "3  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "4  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Adam Smith; B12; B13; B25; B53; Behavioral eco...   \n",
       "1                                                NaN   \n",
       "2  Artificial intelligence; Economic planning; H1...   \n",
       "3                                                NaN   \n",
       "4  asset size; capital market; firm size; mission...   \n",
       "\n",
       "                                           Publisher  \\\n",
       "0                                           Springer   \n",
       "1                                 Taylor and Francis   \n",
       "2  Springer Science and Business Media Deutschlan...   \n",
       "3                              Academy of Management   \n",
       "4                                            Sciendo   \n",
       "\n",
       "                          Open Access  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                                 NaN  \n",
       "3  All Open Access; Green Open Access  \n",
       "4   All Open Access; Gold Open Access  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "scopus_df = pd.read_csv(\"../data/raw/scopus.csv\")\n",
    "\n",
    "scopus_df['Source title'] = scopus_df['Source title'].replace(\"The Review of Austrian Economics\", \"Review of Austrian Economics\")\n",
    "\n",
    "scopus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read TEI files!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df, refs_df = read_tei_papers(tei_path)\n",
    "\n",
    "assert papers_df['paper_id'].is_unique, \"Duplicate paper_id values found in papers_df\"\n",
    "\n",
    "print(\"Read TEI files!\")\n",
    "\n",
    "papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>reference_count</th>\n",
       "      <th>source title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Historical Intervention in the \"Opportunity ...</td>\n",
       "      <td>A-Historical-Intervention-in-the-Opportunity-W...</td>\n",
       "      <td>283</td>\n",
       "      <td>106</td>\n",
       "      <td>Entrepreneurship: Theory and Practice</td>\n",
       "      <td>90.604027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                              title  \\\n",
       "0         1  A Historical Intervention in the \"Opportunity ...   \n",
       "\n",
       "                                            filename  sentence_count  \\\n",
       "0  A-Historical-Intervention-in-the-Opportunity-W...             283   \n",
       "\n",
       "   reference_count                           source title  similarity  \n",
       "0              106  Entrepreneurship: Theory and Practice   90.604027  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Normalização básica\n",
    "papers_df[\"title_norm\"] = papers_df[\"title\"].str.lower().str.strip()\n",
    "scopus_df[\"title_norm\"] = scopus_df[\"Title\"].str.lower().str.strip()\n",
    "\n",
    "scopus_titles = scopus_df[\"title_norm\"].tolist()\n",
    "\n",
    "def get_best_scopus_source(title):\n",
    "    if pd.isna(title):\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    match, score, idx = process.extractOne(\n",
    "        title,\n",
    "        scopus_titles,\n",
    "        scorer=fuzz.token_sort_ratio  # melhor para títulos acadêmicos\n",
    "    )\n",
    "\n",
    "    source_title = scopus_df.iloc[idx][\"Source title\"]\n",
    "    return pd.Series([source_title, score])\n",
    "\n",
    "# Aplica fuzzy matching\n",
    "papers_df[[\"source title\", \"similarity\"]] = (\n",
    "    papers_df[\"title_norm\"]\n",
    "    .apply(get_best_scopus_source)\n",
    ")\n",
    "\n",
    "# (Opcional) filtro de qualidade\n",
    "SIMILARITY_THRESHOLD = 85\n",
    "papers_df.loc[papers_df[\"similarity\"] < SIMILARITY_THRESHOLD, \"scopus_source_title\"] = None\n",
    "\n",
    "# Limpeza\n",
    "papers_df = papers_df.drop(columns=[\"title_norm\"])\n",
    "papers_df = papers_df.drop(columns=[\"scopus_source_title\"])\n",
    "\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating spreadsheets...\n",
      "Percentage of NA in 'source title': 0.00%\n"
     ]
    }
   ],
   "source": [
    "#papers_df = papers_df.drop(columns=['Title'])\n",
    "papers_df = papers_df.sort_values(by='paper_id', ascending=False)\n",
    "\n",
    "refs_df = pd.merge(refs_df, papers_df, on='paper_id', how='left')\n",
    "\n",
    "print(\"Creating spreadsheets...\")\n",
    "papers_df.to_csv(\"../data/processed/papers.csv\", index=False)\n",
    "refs_df.to_csv(\"../data/processed/refs.csv\")\n",
    "\n",
    "na_percentage = papers_df['source title'].isna().mean() * 100\n",
    "print(f\"Percentage of NA in 'source title': {na_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>reference_count</th>\n",
       "      <th>source title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Historical Intervention in the \"Opportunity ...</td>\n",
       "      <td>A-Historical-Intervention-in-the-Opportunity-W...</td>\n",
       "      <td>283</td>\n",
       "      <td>106</td>\n",
       "      <td>Entrepreneurship: Theory and Practice</td>\n",
       "      <td>90.604027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                              title  \\\n",
       "0         1  A Historical Intervention in the \"Opportunity ...   \n",
       "\n",
       "                                            filename  sentence_count  \\\n",
       "0  A-Historical-Intervention-in-the-Opportunity-W...             283   \n",
       "\n",
       "   reference_count                           source title  similarity  \n",
       "0              106  Entrepreneurship: Theory and Practice   90.604027  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = papers_df[papers_df.title == 'A Historical Intervention in the \"Opportunity Wars\": Forgotten Scholarship, the Discovery/Creation Disruption, and Moving Forward by Looking Backward'].iloc[0]\n",
    "\n",
    "assert paper['source title'] == 'Entrepreneurship: Theory and Practice'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
