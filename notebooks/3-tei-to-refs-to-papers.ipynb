{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEscreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\\n'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tei_path = \"../data/interim/test_tei\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_year(citation):\n",
    "    match = re.search(r'\\b(\\d{4})\\b', citation)\n",
    "    return (int(match.group(1)), None) if match else (None, None)\n",
    "\n",
    "\n",
    "def extract_year_and_page(citation):\n",
    "\n",
    "    if citation is None:\n",
    "        return (None, None)\n",
    "\n",
    "    # Use a regular expression to extract the year and page\n",
    "    match = re.search(\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?)[:\\s,]*pp?\\.\\s*(\\d+)(?:-\\d+)?|\"  # Match for \"pp.\" or \"p.\" with year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?):\\s*(\\d+)|\"                     # Match for \":\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*(\\d+)-\\d+|\"                # Match for page range without \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*(\\d+)(?:-\\d+)?|\"           # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" without explicit parentheses\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?)\\s*:\\s*(\\d+)|\"                  # Match for \": Page\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*)pp?\\.\\s*(\\d+)|\"                                # Match for \"pp.\" without year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*chap\\.\\s*(\\d+)\",           # Match for \"chap.\" format\n",
    "        citation\n",
    "    )\n",
    "    if match:\n",
    "        if match.group(1):  # Match for \"pp.\" or \"p.\" with year\n",
    "            year = match.group(1)\n",
    "            page = int(match.group(2))\n",
    "        elif match.group(3):  # Match for \":\" format\n",
    "            year = match.group(3)\n",
    "            page = int(match.group(4))\n",
    "        elif match.group(5):  # Match for single \"p.\" with year\n",
    "            year = match.group(5)\n",
    "            page = int(match.group(6))\n",
    "        elif match.group(7):  # Match for range without \"pp.\" or \"p.\"\n",
    "            year = match.group(7)\n",
    "            page = int(match.group(8))\n",
    "        elif match.group(9):  # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "            year = match.group(9)\n",
    "            page = int(match.group(10))\n",
    "        elif match.group(11):  # Match for \"p.\" without year and page\n",
    "            year = match.group(11)\n",
    "            page = int(match.group(12))\n",
    "        elif match.group(13):  # Match for \": Page\" format\n",
    "            year = match.group(13)\n",
    "            page = int(match.group(14))\n",
    "        elif match.group(15):  # Match for \"pp.\" without year\n",
    "            year = None\n",
    "            page = int(match.group(15))\n",
    "        elif match.group(16):  # Match for \"chap.\" format\n",
    "            year = match.group(16)\n",
    "            page = int(match.group(17))\n",
    "        \n",
    "        # Strip the letter suffix from the year before returning (if present)\n",
    "        if year:\n",
    "            year = int(re.match(r'\\d{4}', year).group())\n",
    "\n",
    "        return year, page\n",
    "    else:\n",
    "        return extract_year(citation)  # Return None if the format doesn't match\n",
    "    \n",
    "\n",
    "# Test the function\n",
    "assert extract_year_and_page(\"Mises (1949, p.258)\") == (1949, 258)\n",
    "assert extract_year_and_page(\"(Mises, 1996, pp. 538-86)\") == (1996, 538)\n",
    "assert extract_year_and_page(\"(von Mises, 1963, p.254)\") == (1963, 254)\n",
    "assert extract_year_and_page(\"(Mises, 1920, 121-122)\") == (1920, 121)\n",
    "assert extract_year_and_page(\"(Mises 1949, 236-237)\") == (1949, 236)\n",
    "assert extract_year_and_page(\"(Mises 1920, 109)\") == (1920, 109)\n",
    "assert extract_year_and_page(\"(Mises 1920, p.162)\") == (1920, 162)\n",
    "assert extract_year_and_page(\"(von Mises, 1949: 351)\") == (1949, 351)\n",
    "assert extract_year_and_page(\"(Mises 1966: 493)\") == (1966, 493)\n",
    "assert extract_year_and_page(\"(von Mises 1998, p. 270)\") == (1998, 270)\n",
    "assert extract_year_and_page(\"Mises 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"Mises 1985b, p. 236\") == (1985, 236)\n",
    "assert extract_year_and_page(\"Mises 1957b, 372\") == (1957, 372)\n",
    "assert extract_year_and_page(\"Mises, pp. 105-6;\") == (None, 105)\n",
    "assert extract_year_and_page(\"(Mises, 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949, pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949 , pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(C Berg 2022)\") == (2022, None)\n",
    "assert extract_year_and_page(\"Hayek (1976:71)\") == (1976, 71)\n",
    "assert extract_year_and_page(\"According to Mises ([1949] 1998: 116)\") == (1998, 116)\n",
    "\n",
    "# (Mises 1998, 419–21, 545–47)\n",
    "\n",
    "assert extract_year_and_page(None) == (None, None)\n",
    "assert extract_year_and_page(\"[and]\") == (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_author(ref):\n",
    "    if ref is None:\n",
    "        return None\n",
    "\n",
    "    match = re.search(r\"([A-Za-z][A-Za-z\\s\\.]+?)(?=\\s\\d{4}|\\s\\[|\\s\\(|,|:|\\))\", ref)\n",
    "    if match:\n",
    "        name = match.group(1).strip()\n",
    "\n",
    "        lowercase_particles = {\"der\", \"de\", \"von\"}\n",
    "        ignore_words = {\"et\", \"al.\"}\n",
    "\n",
    "        def normalize(word):\n",
    "            w = word.lower()\n",
    "\n",
    "            if w in lowercase_particles:\n",
    "                return w\n",
    "            if w in ignore_words:\n",
    "                return word\n",
    "            if w.startswith(\"mc\") and len(w) > 2:\n",
    "                return \"Mc\" + w[2].upper() + w[3:]\n",
    "            return word.capitalize()\n",
    "\n",
    "        temp = \" \".join(normalize(word) for word in name.split())\n",
    "\n",
    "        temp = (\n",
    "            temp.replace(\"von Mises\", \"Mises\")\n",
    "                .replace(\"L V Mises\", \"Mises\")\n",
    "                .replace(\"L Mises\", \"Mises\")\n",
    "                .replace(\"von Hayek\", \"Hayek\")\n",
    "                .replace(\"F A Hayek\", \"Hayek\")\n",
    "                .replace(\"K Marx\", \"Marx\")\n",
    "                .replace(\" et al.\", \"\")\n",
    "        )\n",
    "\n",
    "        temp = temp.split(\" And\")[0] if \" And\" in temp else temp\n",
    "        return temp\n",
    "\n",
    "    match_single_word = re.search(r\"([A-Za-z]+(?:'s)?)(?=\\s\\d{4}|\\s\\(|:|\\))\", ref)\n",
    "    if match_single_word:\n",
    "        name = match_single_word.group(1).replace(\"'s\", \"\")\n",
    "        return name.capitalize()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Test cases\n",
    "assert extract_author(\"Johnson, 1999;\") == \"Johnson\"             \n",
    "assert extract_author(\"Jouvenel (1961)\") == \"Jouvenel\"\n",
    "assert extract_author(\"Keen 2011\") == \"Keen\"\n",
    "assert extract_author(\"(Menger, [1981])\") == \"Menger\"\n",
    "assert extract_author(\"von Mises (1949)\") == \"Mises\"\n",
    "assert extract_author(\"Von Hayek (1949)\") == \"Hayek\"\n",
    "assert extract_author(\"de Broglie (1924)\") == \"de Broglie\"\n",
    "assert extract_author(\"Allen 2005)\") == \"Allen\"\n",
    "assert extract_author(\"Folta's (1998)\") == \"Folta\"\n",
    "assert extract_author(\"Boettke et al. (1998)\") == \"Boettke\"\n",
    "assert extract_author(\"Floss and Klein (1998)\") == \"Floss\"\n",
    "assert extract_author(\"Floss And Klein (1998)\") == \"Floss\"\n",
    "assert extract_author(\"(Von Mises 1949 )\") == \"Mises\"\n",
    "assert extract_author(\"(L V Mises 1949 )\") == \"Mises\" \n",
    "assert extract_author(\"(L Mises 1998 )\") == \"Mises\"\n",
    "assert extract_author(\"(L Von Mises 1998 )\") == \"Mises\"\n",
    "assert extract_author(\"Van der Waals (1873)\") == \"Van der Waals\"\n",
    "assert extract_author(\"(McGrath et al., 2004: 96)\") == \"McGrath\"\n",
    "\n",
    "assert extract_author(None) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Gere código python que cria uma classe Reference que tem atributos: raw, context, sentence_seq_number, sentence_id, author, page, year. \n",
    "raw, context, e sentence_id são passados pelo construtor.\n",
    "page e year são obtidos a partir da chamada à extract_year_and_page(raw), que retorna uma tupla (year, page).\n",
    "author é obtido a partir da chamada a extract_author(raw).\n",
    "'''\n",
    "\n",
    "class Reference:\n",
    "    def __init__(self, raw, context, sentence_seq_number, sentence_id):\n",
    "        self.raw = raw\n",
    "        self.context = context\n",
    "        self.sentence_seq_number = sentence_seq_number\n",
    "        self.sentence_id = sentence_id\n",
    "\n",
    "        self.year, self.page = extract_year_and_page(raw)\n",
    "        self.author = extract_author(raw)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Reference(raw={self.raw!r}, context={self.context!r}, \"\n",
    "                f\"sentence_id={self.sentence_id!r}, year={self.year!r}, page={self.page!r})\")\n",
    "\n",
    "\n",
    "\n",
    "ref = Reference(\"(L Von Mises 1949 , pp. 393)\", \"\",  3, \"123\")\n",
    "assert ref.year == 1949\n",
    "assert ref.page == 393\n",
    "assert ref.sentence_seq_number == 3\n",
    "assert ref.author == \"Mises\"\n",
    "\n",
    "\n",
    "ref = Reference(None, None, None, None)\n",
    "assert ref.year == None\n",
    "assert ref.page == None\n",
    "assert ref.sentence_seq_number == None\n",
    "assert ref.author == None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "\n",
    "Write a function parse_tei(tei_filepath) that opens the TEI XML file and counts the number of biblStruct entries. \n",
    "Also, count the number of <s></s> entries. \n",
    "Return four values:  \n",
    "1. The paper title, available in teiHeader / fileDesc / titleStmt / title.\n",
    "2. the number of s entries\n",
    "3. the number of biblStruct entries\n",
    "4. a list of Reference objects.  \n",
    "\n",
    "Each reference object has a field raw, a field sentence_seq_number, a field sentence_id and a field context. \n",
    "\n",
    "Raw should be filled with the text inside the ref tag; context should be filled with the text on the parent <s> tag. \n",
    "sentence_seq should be filled with the sequential count of the <s> in the XML file, e.g, sentence_seq = 10 if s is the 10th sentence in the file.\n",
    "sentence_id should be filled with the value of the property \"xml:id\" from the parent <s> tag.\n",
    "\n",
    "'''\n",
    "\n",
    "from lxml import etree\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def parse_tei(tei_filepath: str) -> Tuple[str, int, int, List[Reference]]:\n",
    "    # Parse the XML\n",
    "    parser = etree.XMLParser(ns_clean=True)\n",
    "    tree = etree.parse(tei_filepath, parser)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # TEI namespace (if any)\n",
    "    nsmap = root.nsmap.copy()\n",
    "    nsmap['tei'] = nsmap.get(None, 'http://www.tei-c.org/ns/1.0')\n",
    "\n",
    "    # 1. Paper title\n",
    "    title_xpath = './/tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title'\n",
    "    title_elem = root.find(title_xpath, namespaces=nsmap)\n",
    "    title = title_elem.text.strip() if title_elem is not None and title_elem.text is not None else \"Unknown Title\"\n",
    "\n",
    "    # 2. Count number of <s> entries\n",
    "    s_xpath = './/tei:s'\n",
    "    s_elems = root.findall(s_xpath, namespaces=nsmap)\n",
    "    num_s = len(s_elems)\n",
    "\n",
    "    # 3. Count number of <biblStruct> entries\n",
    "    bibl_xpath = './/tei:biblStruct'\n",
    "    bibl_elems = root.findall(bibl_xpath, namespaces=nsmap)\n",
    "    num_bibl = len(bibl_elems)\n",
    "\n",
    "    # 4. References\n",
    "    references = []\n",
    "    for idx, s in enumerate(s_elems, start=1):\n",
    "        sentence_id = s.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "        context_text = ''.join(s.itertext()).strip()\n",
    "\n",
    "        for ref in s.findall('.//tei:ref', namespaces=nsmap):\n",
    "            ref_text = ''.join(ref.itertext()).strip()\n",
    "            references.append(Reference(\n",
    "                raw=ref_text,\n",
    "                sentence_seq_number=idx,\n",
    "                sentence_id=sentence_id,\n",
    "                context=context_text\n",
    "            ))\n",
    "\n",
    "    return title, num_s, num_bibl, references\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE 1\n",
    "\n",
    "paper_path = \"../data/interim/tei/A-Historical-Intervention-in-the-Opportunity-Wars-Forgotten-Scholarship-the-DiscoveryCreation-Disruption-and-Moving-Forward-by-Looking-Backward_2023_SAGE-Publications-Ltd.pdf.grobid.tei.xml\"\n",
    "title, sentence_count, reference_count, refs = parse_tei(paper_path) \n",
    "\n",
    "assert sentence_count == 283\n",
    "assert reference_count == 106\n",
    "assert len(refs) == 222\n",
    "assert title == \"A Historical Intervention in the \\\"Opportunity Wars\\\": Forgotten Scholarship, the Discovery/Creation Disruption, and Moving Forward by Looking Backward\"\n",
    "\n",
    "assert refs[0].sentence_id == '_paHYmXc'\n",
    "assert refs[0].sentence_seq_number == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e cria dois dataframes.\n",
    "Um pandas df chamado \"papers_df\" em que cada registro tem a coluna paper_id, que é um número sequencial, além das colunas title, filename, sentence_count, reference_count.\n",
    "Para cada arquivo, invoque parse_tei(tei_filepath), que retorna sentence_count, reference_count e refs.  \n",
    "Adicione sentence_count e reference_count no papers_df.  \n",
    "Add a try-catch loop that catches exceptions in XML Parsing.\n",
    "Ao outro df, chamado refs_df, adicione todos os refs. Um ref é um objeto Reference que tem os campos raw, context, sentence_id, sentence_seq_number e page.\n",
    "Cada campo deve ser uma coluna em refs_df.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from xml.etree.ElementTree import ParseError\n",
    "\n",
    "\n",
    "def read_tei_papers(path: str):\n",
    "    papers = []\n",
    "    refs = []\n",
    "\n",
    "    paper_id = 1\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tei_filepath = os.path.join(path, filename)\n",
    "            try:\n",
    "                title, sentence_count, reference_count, ref_list = parse_tei(tei_filepath)\n",
    "\n",
    "                # Adiciona entrada ao papers_df\n",
    "                papers.append({\n",
    "                    \"paper_id\": paper_id,\n",
    "                    \"title\": title,\n",
    "                    \"filename\": filename,\n",
    "                    \"sentence_count\": sentence_count,\n",
    "                    \"reference_count\": reference_count\n",
    "                })\n",
    "\n",
    "                # Adiciona entradas ao refs_df\n",
    "                for ref in ref_list:\n",
    "                    refs.append({\n",
    "                        \"paper_id\": paper_id,\n",
    "                        \"raw\": ref.raw,\n",
    "                        \"context\": ref.context,\n",
    "                        \"sentence_id\": ref.sentence_id,\n",
    "                        \"sentence_seq_number\": ref.sentence_seq_number,\n",
    "                        \"author\": ref.author,\n",
    "                        \"page\": ref.page,\n",
    "                        \"year\": ref.year\n",
    "                    })\n",
    "\n",
    "                paper_id += 1\n",
    "\n",
    "            except ParseError as e:\n",
    "                print(f\"Erro ao processar {filename}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro desconhecido em {filename}: {e}\")\n",
    "\n",
    "    # Cria os DataFrames\n",
    "    papers_df = pd.DataFrame(papers)\n",
    "    refs_df = pd.DataFrame(refs)\n",
    "\n",
    "    return papers_df, refs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Source title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Link</th>\n",
       "      <th>Author Keywords</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Open Access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two worlds collide: A review essay of Humanomi...</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>10.1007/s11138-022-00610-y</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Adam Smith; B12; B13; B25; B53; Behavioral eco...</td>\n",
       "      <td>Springer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MODERN AUSTRIAN ECONOMICS: Archaeology of a Re...</td>\n",
       "      <td>Modern Austrian Economics: Archaeology of a Re...</td>\n",
       "      <td>10.4324/9781003549666</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taylor and Francis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial intelligence and economic planning</td>\n",
       "      <td>AI and Society</td>\n",
       "      <td>10.1007/s00146-022-01523-x</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>Artificial intelligence; Economic planning; H1...</td>\n",
       "      <td>Springer Science and Business Media Deutschlan...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"WHAT IS AN OPPORTUNITY?\": FROM THEORETICAL MY...</td>\n",
       "      <td>Academy of Management Review</td>\n",
       "      <td>10.5465/amr.2020.0335</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academy of Management</td>\n",
       "      <td>All Open Access; Green Open Access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Organizational Inefficiency Adversely Affe...</td>\n",
       "      <td>Studia Universitatis Vasile Goldis Arad, Econo...</td>\n",
       "      <td>10.2478/sues-2024-0017</td>\n",
       "      <td>https://www.scopus.com/inward/record.uri?eid=2...</td>\n",
       "      <td>asset size; capital market; firm size; mission...</td>\n",
       "      <td>Sciendo</td>\n",
       "      <td>All Open Access; Gold Open Access</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Two worlds collide: A review essay of Humanomi...   \n",
       "1  MODERN AUSTRIAN ECONOMICS: Archaeology of a Re...   \n",
       "2      Artificial intelligence and economic planning   \n",
       "3  \"WHAT IS AN OPPORTUNITY?\": FROM THEORETICAL MY...   \n",
       "4  How Organizational Inefficiency Adversely Affe...   \n",
       "\n",
       "                                        Source title  \\\n",
       "0                       Review of Austrian Economics   \n",
       "1  Modern Austrian Economics: Archaeology of a Re...   \n",
       "2                                     AI and Society   \n",
       "3                       Academy of Management Review   \n",
       "4  Studia Universitatis Vasile Goldis Arad, Econo...   \n",
       "\n",
       "                          DOI  \\\n",
       "0  10.1007/s11138-022-00610-y   \n",
       "1       10.4324/9781003549666   \n",
       "2  10.1007/s00146-022-01523-x   \n",
       "3       10.5465/amr.2020.0335   \n",
       "4      10.2478/sues-2024-0017   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "1  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "2  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "3  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "4  https://www.scopus.com/inward/record.uri?eid=2...   \n",
       "\n",
       "                                     Author Keywords  \\\n",
       "0  Adam Smith; B12; B13; B25; B53; Behavioral eco...   \n",
       "1                                                NaN   \n",
       "2  Artificial intelligence; Economic planning; H1...   \n",
       "3                                                NaN   \n",
       "4  asset size; capital market; firm size; mission...   \n",
       "\n",
       "                                           Publisher  \\\n",
       "0                                           Springer   \n",
       "1                                 Taylor and Francis   \n",
       "2  Springer Science and Business Media Deutschlan...   \n",
       "3                              Academy of Management   \n",
       "4                                            Sciendo   \n",
       "\n",
       "                          Open Access  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                                 NaN  \n",
       "3  All Open Access; Green Open Access  \n",
       "4   All Open Access; Gold Open Access  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "scopus_df = pd.read_csv(\"../data/raw/scopus.csv\")\n",
    "\n",
    "scopus_df['Source title'] = scopus_df['Source title'].replace(\"The Review of Austrian Economics\", \"Review of Austrian Economics\")\n",
    "\n",
    "scopus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read TEI files!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df, refs_df = read_tei_papers(tei_path)\n",
    "\n",
    "assert papers_df['paper_id'].is_unique, \"Duplicate paper_id values found in papers_df\"\n",
    "\n",
    "print(\"Read TEI files!\")\n",
    "\n",
    "papers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>reference_count</th>\n",
       "      <th>source title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Historical Intervention in the \"Opportunity ...</td>\n",
       "      <td>A-Historical-Intervention-in-the-Opportunity-W...</td>\n",
       "      <td>283</td>\n",
       "      <td>106</td>\n",
       "      <td>Entrepreneurship: Theory and Practice</td>\n",
       "      <td>90.604027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                              title  \\\n",
       "0         1  A Historical Intervention in the \"Opportunity ...   \n",
       "\n",
       "                                            filename  sentence_count  \\\n",
       "0  A-Historical-Intervention-in-the-Opportunity-W...             283   \n",
       "\n",
       "   reference_count                           source title  similarity  \n",
       "0              106  Entrepreneurship: Theory and Practice   90.604027  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Normalização básica\n",
    "papers_df[\"title_norm\"] = papers_df[\"title\"].str.lower().str.strip()\n",
    "scopus_df[\"title_norm\"] = scopus_df[\"Title\"].str.lower().str.strip()\n",
    "\n",
    "scopus_titles = scopus_df[\"title_norm\"].tolist()\n",
    "\n",
    "def get_best_scopus_source(title):\n",
    "    if pd.isna(title):\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "    match, score, idx = process.extractOne(\n",
    "        title,\n",
    "        scopus_titles,\n",
    "        scorer=fuzz.token_sort_ratio  # melhor para títulos acadêmicos\n",
    "    )\n",
    "\n",
    "    source_title = scopus_df.iloc[idx][\"Source title\"]\n",
    "    return pd.Series([source_title, score])\n",
    "\n",
    "# Aplica fuzzy matching\n",
    "papers_df[[\"source title\", \"similarity\"]] = (\n",
    "    papers_df[\"title_norm\"]\n",
    "    .apply(get_best_scopus_source)\n",
    ")\n",
    "\n",
    "# (Opcional) filtro de qualidade\n",
    "SIMILARITY_THRESHOLD = 85\n",
    "papers_df.loc[papers_df[\"similarity\"] < SIMILARITY_THRESHOLD, \"scopus_source_title\"] = None\n",
    "\n",
    "# Limpeza\n",
    "papers_df = papers_df.drop(columns=[\"title_norm\"])\n",
    "papers_df = papers_df.drop(columns=[\"scopus_source_title\"])\n",
    "\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating spreadsheets...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../data/processed/refs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[197], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating spreadsheets...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m papers_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/papers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mrefs_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/processed/refs.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m na_percentage \u001b[38;5;241m=\u001b[39m papers_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of NA in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource title\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mna_percentage\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3989\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3978\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3980\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3981\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3982\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3986\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3987\u001b[0m )\n\u001b[1;32m-> 3989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4006\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../data/processed/refs.csv'"
     ]
    }
   ],
   "source": [
    "#papers_df = papers_df.drop(columns=['Title'])\n",
    "papers_df = papers_df.sort_values(by='paper_id', ascending=False)\n",
    "\n",
    "refs_df = pd.merge(refs_df, papers_df, on='paper_id', how='left')\n",
    "\n",
    "print(\"Creating spreadsheets...\")\n",
    "papers_df.to_csv(\"../data/processed/papers.csv\", index=False)\n",
    "refs_df.to_csv(\"../data/processed/refs.csv\")\n",
    "\n",
    "na_percentage = papers_df['source title'].isna().mean() * 100\n",
    "print(f\"Percentage of NA in 'source title': {na_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = papers_df[papers_df.title == 'A Historical Intervention in the \"Opportunity Wars\": Forgotten Scholarship, the Discovery/Creation Disruption, and Moving Forward by Looking Backward'].iloc[0]\n",
    "\n",
    "assert paper['source title'] == 'Entrepreneurship: Theory and Practice'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
