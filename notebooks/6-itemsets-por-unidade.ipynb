{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265726 entries, 0 to 265725\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   paper_id              265726 non-null  int64  \n",
      " 1   raw                   265644 non-null  object \n",
      " 2   co_cited_count        265726 non-null  int64  \n",
      " 3   section_id            259027 non-null  object \n",
      " 4   paragraph_id          265684 non-null  object \n",
      " 5   sentence_id           265726 non-null  object \n",
      " 6   sentence_seq_number   265726 non-null  int64  \n",
      " 7   reference_seq_number  265726 non-null  int64  \n",
      " 8   author                227628 non-null  object \n",
      " 9   page                  74403 non-null   float64\n",
      " 10  year                  222883 non-null  float64\n",
      " 11  title                 265726 non-null  object \n",
      " 12  filename              265726 non-null  object \n",
      " 13  sentence_count        265726 non-null  int64  \n",
      " 14  reference_count       265726 non-null  int64  \n",
      " 15  source title          237907 non-null  object \n",
      " 16  similarity            265726 non-null  float64\n",
      "dtypes: float64(3), int64(6), object(8)\n",
      "memory usage: 34.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "refs_df = pd.read_csv(\n",
    "    \"../data/processed/refs.csv\",\n",
    "    usecols=lambda c: c != \"context\"\n",
    ")\n",
    "\n",
    "refs_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>raw</th>\n",
       "      <th>co_cited_count</th>\n",
       "      <th>section_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_seq_number</th>\n",
       "      <th>reference_seq_number</th>\n",
       "      <th>author</th>\n",
       "      <th>page</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>reference_count</th>\n",
       "      <th>source title</th>\n",
       "      <th>similarity</th>\n",
       "      <th>tradition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Streissler (1972)</td>\n",
       "      <td>0</td>\n",
       "      <td>_gzuY8cP</td>\n",
       "      <td>_NwgSU35</td>\n",
       "      <td>_TMX2wdg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Streissler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>Unknown Title</td>\n",
       "      <td>10.1002.9780470999059.ch17.pdf.grobid.tei.xml</td>\n",
       "      <td>298</td>\n",
       "      <td>20</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>non-classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(Menger, [1981]  1871, p. 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Menger</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Unknown Title</td>\n",
       "      <td>10.1002.9780470999059.ch17.pdf.grobid.tei.xml</td>\n",
       "      <td>298</td>\n",
       "      <td>20</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>traditional-austrian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(Menger, [1981]  1871, p. 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Menger</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Unknown Title</td>\n",
       "      <td>10.1002.9780470999059.ch17.pdf.grobid.tei.xml</td>\n",
       "      <td>298</td>\n",
       "      <td>20</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>traditional-austrian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1871, p. 49)</td>\n",
       "      <td>1</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>Unknown Title</td>\n",
       "      <td>10.1002.9780470999059.ch17.pdf.grobid.tei.xml</td>\n",
       "      <td>298</td>\n",
       "      <td>20</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>non-classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(Menger, [1981] 1871, p. 48)</td>\n",
       "      <td>0</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_54sgkMV</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>Menger</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Unknown Title</td>\n",
       "      <td>10.1002.9780470999059.ch17.pdf.grobid.tei.xml</td>\n",
       "      <td>298</td>\n",
       "      <td>20</td>\n",
       "      <td>Review of Austrian Economics</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>traditional-austrian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                            raw  co_cited_count section_id  \\\n",
       "0         1              Streissler (1972)               0   _gzuY8cP   \n",
       "1         1  (Menger, [1981]  1871, p. 49)               1   _NytzfyY   \n",
       "2         1  (Menger, [1981]  1871, p. 49)               1   _NytzfyY   \n",
       "3         1                   1871, p. 49)               1   _NytzfyY   \n",
       "4         1   (Menger, [1981] 1871, p. 48)               0   _NytzfyY   \n",
       "\n",
       "  paragraph_id sentence_id  sentence_seq_number  reference_seq_number  \\\n",
       "0     _NwgSU35    _TMX2wdg                    4                     1   \n",
       "1     _Z99Bvn5    _aJz9uAb                   10                     2   \n",
       "2     _Z99Bvn5    _aJz9uAb                   10                     2   \n",
       "3     _Z99Bvn5    _aJz9uAb                   10                     3   \n",
       "4     _Z99Bvn5    _54sgkMV                   11                     4   \n",
       "\n",
       "       author  page    year          title  \\\n",
       "0  Streissler   NaN  1972.0  Unknown Title   \n",
       "1      Menger  49.0  1981.0  Unknown Title   \n",
       "2      Menger  49.0  1981.0  Unknown Title   \n",
       "3         NaN  49.0  1871.0  Unknown Title   \n",
       "4      Menger  48.0  1981.0  Unknown Title   \n",
       "\n",
       "                                        filename  sentence_count  \\\n",
       "0  10.1002.9780470999059.ch17.pdf.grobid.tei.xml             298   \n",
       "1  10.1002.9780470999059.ch17.pdf.grobid.tei.xml             298   \n",
       "2  10.1002.9780470999059.ch17.pdf.grobid.tei.xml             298   \n",
       "3  10.1002.9780470999059.ch17.pdf.grobid.tei.xml             298   \n",
       "4  10.1002.9780470999059.ch17.pdf.grobid.tei.xml             298   \n",
       "\n",
       "   reference_count                  source title  similarity  \\\n",
       "0               20  Review of Austrian Economics   44.444444   \n",
       "1               20  Review of Austrian Economics   44.444444   \n",
       "2               20  Review of Austrian Economics   44.444444   \n",
       "3               20  Review of Austrian Economics   44.444444   \n",
       "4               20  Review of Austrian Economics   44.444444   \n",
       "\n",
       "              tradition  \n",
       "0        non-classified  \n",
       "1  traditional-austrian  \n",
       "2  traditional-austrian  \n",
       "3        non-classified  \n",
       "4  traditional-austrian  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. L√™ o CSV com o mapeamento autor ‚Üí tradi√ß√£o\n",
    "author_school_df = pd.read_csv(\n",
    "    \"../notebooks/map-author-school.csv\"\n",
    ")\n",
    "\n",
    "# Normaliza√ß√£o b√°sica\n",
    "author_school_df[\"author\"] = author_school_df[\"author\"].str.strip()\n",
    "refs_df[\"author\"] = refs_df[\"author\"].str.strip()\n",
    "\n",
    "# 2. Left join via author\n",
    "refs_df = (\n",
    "    refs_df\n",
    "    .merge(\n",
    "        author_school_df,\n",
    "        on=\"author\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Se tradition n√£o foi encontrada, marcar como 'non-classified'\n",
    "refs_df[\"tradition\"] = refs_df[\"tradition\"].fillna(\"non-classified\")\n",
    "\n",
    "refs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author       tradition                  \n",
       "NaN          non-classified                 38098\n",
       "Hayek        traditional-austrian           12562\n",
       "Mises        traditional-austrian            7754\n",
       "Kirzner      contemporary-austrian           3013\n",
       "Rothbard     traditional-austrian            2647\n",
       "Menger       traditional-austrian            2580\n",
       "Friedman     chicago                         2116\n",
       "Schumpeter   neoclassical                    1992\n",
       "Boettke      contemporary-austrian           1629\n",
       "Buchanan     public-choice                   1485\n",
       "Smith        classical                       1404\n",
       "Foss         organizational-theory           1289\n",
       "Lachmann     traditional-austrian            1230\n",
       "Keynes       keynesian                       1022\n",
       "Knight       chicago                          933\n",
       "Weber        sociology                        909\n",
       "Shane        non-classified                   823\n",
       "Williamson   new-institutional-economics      779\n",
       "Bylund       contemporary-austrian            762\n",
       "North        classical                        758\n",
       "Coase        chicago                          708\n",
       "Klein        contemporary-austrian            698\n",
       "Hodgson      institutional-economics          638\n",
       "Garrison     contemporary-austrian            629\n",
       "Hoppe        contemporary-austrian            593\n",
       "Lavoie       contemporary-austrian            587\n",
       "Samuelson    keynesian                        530\n",
       "Baumol       non-classified                   514\n",
       "Becker       chicago                          500\n",
       "Salerno      contemporary-austrian            498\n",
       "Simon        non-classified                   498\n",
       "Sarasvathy   non-classified                   495\n",
       "Wagner       contemporary-austrian            487\n",
       "Anderson     non-classified                   472\n",
       "Block        contemporary-austrian            470\n",
       "Ostrom       non-classified                   418\n",
       "Wicksell     neoclassical                     418\n",
       "Taylor       non-classified                   416\n",
       "Nelson       non-classified                   416\n",
       "Jacobs       non-classified                   411\n",
       "Lewin        non-classified                   404\n",
       "Langlois     non-classified                   403\n",
       "White        non-classified                   389\n",
       "Tullock      public-choice                    377\n",
       "Marx         marxism                          371\n",
       "Arrow        non-classified                   369\n",
       "Vanberg      non-classified                   368\n",
       "Marshall     non-classified                   367\n",
       "Selgin       non-classified                   363\n",
       "Eucken       non-classified                   358\n",
       "Popper       non-classified                   357\n",
       "Jones        non-classified                   356\n",
       "Stigler      non-classified                   352\n",
       "Alvarez      non-classified                   344\n",
       "Johnson      non-classified                   344\n",
       "Fisher       neoclassical                     343\n",
       "Polanyi      economic-sociology               339\n",
       "Shackle      non-classified                   332\n",
       "Koppl        contemporary-austrian            331\n",
       "McMullen     non-classified                   330\n",
       "Barney       non-classified                   325\n",
       "Wright       non-classified                   325\n",
       "Miller       non-classified                   323\n",
       "Leeson       contemporary-austrian            319\n",
       "Mill         classical                        319\n",
       "Sch√ºtz       non-classified                   315\n",
       "Schutz       non-classified                   315\n",
       "H√ºlsmann     non-classified                   309\n",
       "Brown        non-classified                   309\n",
       "Lucas        chicago                          307\n",
       "Young        non-classified                   302\n",
       "Hall         non-classified                   301\n",
       "Coyne        contemporary-austrian            301\n",
       "Robbins      non-classified                   299\n",
       "Hutt         non-classified                   292\n",
       "Packard      non-classified                   291\n",
       "Holcombe     contemporary-austrian            290\n",
       "Clark        non-classified                   287\n",
       "Horwitz      contemporary-austrian            286\n",
       "Lewis        non-classified                   285\n",
       "Acemoglu     non-classified                   283\n",
       "Bawerk       traditional-austrian             279\n",
       "Hansen       keynesian                        276\n",
       "Machlup      non-classified                   275\n",
       "Caldwell     non-classified                   274\n",
       "Sen          non-classified                   273\n",
       "Neurath      non-classified                   269\n",
       "Martin       non-classified                   265\n",
       "Benson       non-classified                   264\n",
       "Acs          non-classified                   263\n",
       "Gartner      non-classified                   262\n",
       "Mitchell     non-classified                   262\n",
       "Ikeda        non-classified                   259\n",
       "Demsetz      non-classified                   257\n",
       "Witt         non-classified                   254\n",
       "Coleman      non-classified                   252\n",
       "Evans        non-classified                   251\n",
       "Bagus        non-classified                   251\n",
       "Granovetter  economic-sociology               250\n",
       "Caplan       non-classified                   249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "refs_df[['author','tradition']].value_counts(dropna=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275255, 18)\n"
     ]
    }
   ],
   "source": [
    "def filter_top_k_authors(refs_df, k):\n",
    "    \"\"\"\n",
    "    Mant√©m apenas os top-K autores mais frequentes em refs_df.\n",
    "    \n",
    "    Popularidade = n√∫mero de ocorr√™ncias do autor no dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Conta frequ√™ncia por autor\n",
    "    author_counts = (\n",
    "        refs_df[\"author\"]\n",
    "        .value_counts()\n",
    "    )\n",
    "\n",
    "    # 2. Seleciona top-K autores\n",
    "    top_k_authors = set(author_counts.head(k).index)\n",
    "\n",
    "    # 3. Filtra o dataframe\n",
    "    filtered_refs_df = refs_df[\n",
    "        refs_df[\"author\"].isin(top_k_authors)\n",
    "    ].copy()\n",
    "\n",
    "    return filtered_refs_df\n",
    "\n",
    "\n",
    "# Mant√©m apenas os 100 autores mais citados\n",
    "#refs_df = filter_top_k_authors(refs_df, k=200)\n",
    "\n",
    "print(refs_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Hayek         12562\n",
       "Mises          7754\n",
       "Kirzner        3013\n",
       "Rothbard       2647\n",
       "Menger         2580\n",
       "Friedman       2116\n",
       "Schumpeter     1992\n",
       "Boettke        1629\n",
       "Buchanan       1485\n",
       "Smith          1404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_df['author'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mises_refs_df = pd.read_csv(\"../data/processed/mises_refs.csv\")\n",
    "\n",
    "# Seleciona apenas o que interessa do mises_refs_df\n",
    "mises_parts = (\n",
    "    mises_refs_df[\n",
    "        [\"sentence_id\", \"author\", \"human_action_part_number\"]\n",
    "    ]\n",
    "    .dropna(subset=[\"sentence_id\", \"human_action_part_number\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Faz LEFT JOIN em refs_df\n",
    "refs_df = refs_df.merge(\n",
    "    mises_parts,\n",
    "    on=[\"sentence_id\", \"author\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_author_node(row):\n",
    "    if (\n",
    "        row[\"author\"] == \"Mises\"\n",
    "        and pd.notna(row[\"human_action_part_number\"])\n",
    "    ):\n",
    "        return f\"Mises_{(row['human_action_part_number'])}\"\n",
    "    return row[\"author\"]\n",
    "\n",
    "\n",
    "refs_df[\"mises_part\"] = refs_df.apply(build_author_node, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Streissler</td>\n",
       "      <td>_TMX2wdg</td>\n",
       "      <td>_NwgSU35</td>\n",
       "      <td>_gzuY8cP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menger</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menger</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>_aJz9uAb</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menger</td>\n",
       "      <td>_54sgkMV</td>\n",
       "      <td>_Z99Bvn5</td>\n",
       "      <td>_NytzfyY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author sentence_id paragraph_id section_id  paper_id\n",
       "0  Streissler    _TMX2wdg     _NwgSU35   _gzuY8cP         1\n",
       "1      Menger    _aJz9uAb     _Z99Bvn5   _NytzfyY         1\n",
       "2      Menger    _aJz9uAb     _Z99Bvn5   _NytzfyY         1\n",
       "3         NaN    _aJz9uAb     _Z99Bvn5   _NytzfyY         1\n",
       "4      Menger    _54sgkMV     _Z99Bvn5   _NytzfyY         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_df[['author', 'sentence_id', 'paragraph_id', 'section_id', 'paper_id']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author    0.138267\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_df[['author', 'sentence_id', 'paragraph_id', 'section_id', 'paper_id']] \\\n",
    "    .isna() \\\n",
    "    .mean() \\\n",
    "    .sort_values(ascending=False).head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def percentage_units_with_mises(refs_df):\n",
    "    granularities = {\n",
    "        \"sentence\": \"sentence_id\",\n",
    "        \"paragraph\": \"paragraph_id\",\n",
    "        \"section\": \"section_id\",\n",
    "        \"paper\": \"paper_id\",\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for level_name, level_col in granularities.items():\n",
    "\n",
    "        # total de unidades naquele n√≠vel\n",
    "        total_units = (\n",
    "            refs_df[level_col]\n",
    "            .dropna()\n",
    "            .nunique()\n",
    "        )\n",
    "\n",
    "        if total_units == 0:\n",
    "            continue\n",
    "\n",
    "        # unidades que cont√™m Mises\n",
    "        mises_units = (\n",
    "            refs_df.loc[refs_df[\"author\"] == \"Mises\", level_col]\n",
    "            .dropna()\n",
    "            .nunique()\n",
    "        )\n",
    "\n",
    "        percent = 100 * mises_units / total_units\n",
    "\n",
    "        results.append({\n",
    "            \"granularity\": level_name,\n",
    "            \"total_units\": total_units,\n",
    "            \"units_with_mises\": mises_units,\n",
    "            \"percent_with_mises\": percent\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "mises_coverage_df = percentage_units_with_mises(refs_df)\n",
    "mises_coverage_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# --------------------------------------------------\n",
    "# papers que cont√™m Mises\n",
    "# --------------------------------------------------\n",
    "papers_with_mises = set(\n",
    "    refs_df.loc[refs_df[\"author\"] == \"Mises\", \"paper_id\"]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# todos os papers com t√≠tulo\n",
    "# --------------------------------------------------\n",
    "papers_df = (\n",
    "    refs_df[[\"paper_id\", \"title\", \"filename\"]]\n",
    "    .dropna(subset=[\"paper_id\"])\n",
    "    .drop_duplicates(subset=[\"paper_id\"])\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# papers sem Mises\n",
    "# --------------------------------------------------\n",
    "papers_without_mises_df = papers_df[\n",
    "    ~papers_df[\"paper_id\"].isin(papers_with_mises)\n",
    "]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# sorteia um paper\n",
    "# --------------------------------------------------\n",
    "random_row = papers_without_mises_df.sample(n=1, random_state=None)\n",
    "\n",
    "random_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_metrics_by_granularity(\n",
    "    refs_df,\n",
    "    author_a,\n",
    "    author_b,\n",
    "    granularities=(\"sentence_id\", \"paragraph_id\", \"section_id\", \"paper_id\")\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    for g in granularities:\n",
    "        df = refs_df[[g, \"author\"]].dropna()\n",
    "\n",
    "        units = (\n",
    "            df\n",
    "            .groupby(g)[\"author\"]\n",
    "            .agg(set)\n",
    "        )\n",
    "\n",
    "        num_units = len(units)\n",
    "\n",
    "        if num_units == 0:\n",
    "            results.append({\n",
    "                \"granularity\": g,\n",
    "                \"num_units\": 0,\n",
    "                \"support_abs\": 0,\n",
    "                \"support\": 0.0,\n",
    "                \"confidence\": 0.0,\n",
    "                \"lift\": 0.0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        has_a = units.apply(lambda s: author_a in s)\n",
    "        has_b = units.apply(lambda s: author_b in s)\n",
    "\n",
    "        count_a = has_a.sum()\n",
    "        count_b = has_b.sum()\n",
    "        count_ab = (has_a & has_b).sum()\n",
    "\n",
    "        if count_a == 0 or count_b == 0:\n",
    "            confidence = 0.0\n",
    "            lift = 0.0\n",
    "            support = 0.0\n",
    "        else:\n",
    "            support = count_ab / num_units\n",
    "            confidence = count_ab / count_a\n",
    "            lift = confidence / (count_b / num_units)\n",
    "\n",
    "        results.append({\n",
    "            \"granularity\": g,\n",
    "            \"num_units\": num_units,\n",
    "            \"support_abs\": int(count_ab),\n",
    "            \"support\": support,\n",
    "            \"confidence\": confidence,\n",
    "            \"lift\": lift\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pair_metrics_by_granularity(\n",
    "    refs_df,\n",
    "    author_a=\"Lange\",\n",
    "    author_b=\"Mises\"\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_target_stats(refs_df, target_author=\"Mises\"):\n",
    "    granularities = [\"sentence_id\", \"paragraph_id\", \"section_id\", \"paper_id\"]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    for g in granularities:\n",
    "        units = (\n",
    "            refs_df\n",
    "            .dropna(subset=[g, \"author\"])\n",
    "            .groupby(g)[\"author\"]\n",
    "            .apply(set)\n",
    "        )\n",
    "\n",
    "        num_units = len(units)\n",
    "        units_with_target = units.apply(lambda s: target_author in s)\n",
    "        support_target = units_with_target.mean()\n",
    "\n",
    "        stats[g] = {\n",
    "            \"num_units\": num_units,\n",
    "            \"support_target\": support_target,\n",
    "            \"units\": units  # ‚ö†Ô∏è cache estrutural\n",
    "        }\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_metrics_from_cache(\n",
    "    author,\n",
    "    target_author,\n",
    "    target_stats\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for g, data in target_stats.items():\n",
    "        units = data[\"units\"]\n",
    "\n",
    "        both = units.apply(\n",
    "            lambda s: author in s and target_author in s\n",
    "        )\n",
    "\n",
    "        support_abs = both.sum()\n",
    "        support = support_abs / data[\"num_units\"]\n",
    "\n",
    "        support_author = units.apply(lambda s: author in s).mean()\n",
    "\n",
    "        confidence = (\n",
    "            support / support_author\n",
    "            if support_author > 0\n",
    "            else 0.0\n",
    "        )\n",
    "\n",
    "        lift = (\n",
    "            confidence / data[\"support_target\"]\n",
    "            if data[\"support_target\"] > 0\n",
    "            else 0.0\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"granularity\": g,\n",
    "            \"num_units\": data[\"num_units\"],\n",
    "            \"support_abs\": support_abs,\n",
    "            \"support\": support,\n",
    "            \"confidence\": confidence,\n",
    "            \"lift\": lift,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_authors_df(\n",
    "    refs_df,\n",
    "    top_k_authors,\n",
    "    target_author=\"Mises\"\n",
    "):\n",
    "    target_stats = precompute_target_stats(\n",
    "        refs_df,\n",
    "        target_author\n",
    "    )\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for author in top_k_authors:\n",
    "        df = pair_metrics_from_cache(\n",
    "            author,\n",
    "            target_author,\n",
    "            target_stats\n",
    "        )\n",
    "\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df = df.assign(\n",
    "            author=author,\n",
    "            with_author=target_author\n",
    "        )\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    authors_df = pd.concat(dfs, ignore_index=True)[\n",
    "        [\"author\", \"with_author\", \"granularity\",\n",
    "         \"num_units\", \"support_abs\", \"support\",\n",
    "         \"confidence\", \"lift\"]\n",
    "    ]\n",
    "\n",
    "    # üîπ Mapa √∫nico author ‚Üí tradition (vem do refs_df)\n",
    "    author_tradition = (\n",
    "        refs_df[[\"author\", \"tradition\"]]\n",
    "        .dropna(subset=[\"author\"])\n",
    "        .drop_duplicates(subset=[\"author\"])\n",
    "    )\n",
    "\n",
    "    # üîπ Left join\n",
    "    authors_df = authors_df.merge(\n",
    "        author_tradition,\n",
    "        on=\"author\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return authors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_top_k_authors(refs_df, k=20, exclude=(\"Mises\",)):\n",
    "    vc = refs_df[\"author\"].value_counts()\n",
    "    vc = vc.drop(labels=exclude, errors=\"ignore\")\n",
    "    return vc.head(k).index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "K = 1000\n",
    "\n",
    "target_author = \"Mises\"\n",
    "\n",
    "top_k_authors = get_top_k_authors(\n",
    "    refs_df,\n",
    "    k=K,\n",
    "    exclude={target_author}\n",
    ")\n",
    "\n",
    "print(\"Top K authors generated.\")\n",
    "\n",
    "authors_df = build_authors_df(\n",
    "    refs_df,\n",
    "    top_k_authors,\n",
    "    target_author=target_author\n",
    ")\n",
    "\n",
    "authors_df.to_csv(\"../data/processed/author_lifts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Configura√ß√£o\n",
    "# --------------------------------------------------\n",
    "\n",
    "GRANULARITY_ORDER = [\n",
    "    \"sentence_id\",\n",
    "    \"paragraph_id\",\n",
    "    \"section_id\",\n",
    "    \"paper_id\"\n",
    "]\n",
    "\n",
    "def lift_to_sign(lift: float) -> str:\n",
    "    if lift > 1:\n",
    "        return \"+\"\n",
    "    elif lift < 1:\n",
    "        return \"-\"\n",
    "    else:\n",
    "        return \"0\"   # opcional\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Fun√ß√£o principal\n",
    "# --------------------------------------------------\n",
    "\n",
    "def build_pattern_table_from_authors_df(authors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A partir de authors_df (uma linha por author √ó with_author √ó granularidade),\n",
    "    computa:\n",
    "      - pattern de sinais de lift ao longo da granularidade\n",
    "      - count ponderado por support_abs\n",
    "\n",
    "    Retorna tabela ordenada por count (desc):\n",
    "      author | with_author | tradition | pattern | count\n",
    "    \"\"\"\n",
    "\n",
    "    df = authors_df.copy()\n",
    "\n",
    "    # Sinal do lift\n",
    "    df[\"sign\"] = df[\"lift\"].apply(lift_to_sign)\n",
    "\n",
    "    # Garantir ordem das granularidades\n",
    "    df[\"granularity\"] = pd.Categorical(\n",
    "        df[\"granularity\"],\n",
    "        categories=GRANULARITY_ORDER,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Pivot dos sinais\n",
    "    pivot_sign = (\n",
    "        df\n",
    "        .pivot_table(\n",
    "            index=[\"author\", \"with_author\", \"tradition\"],\n",
    "            columns=\"granularity\",\n",
    "            values=\"sign\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "        .add_suffix(\"_sign\")\n",
    "    )\n",
    "\n",
    "    # Pivot do support_abs\n",
    "    pivot_support = (\n",
    "        df\n",
    "        .pivot_table(\n",
    "            index=[\"author\", \"with_author\", \"tradition\"],\n",
    "            columns=\"granularity\",\n",
    "            values=\"support_abs\",\n",
    "            aggfunc=\"sum\"\n",
    "        )\n",
    "        .add_suffix(\"_support\")\n",
    "    )\n",
    "\n",
    "    # Junta tudo\n",
    "    pivot = (\n",
    "        pivot_sign\n",
    "        .join(pivot_support)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Construir pattern usando as colunas *_sign\n",
    "    sign_cols = [f\"{g}_sign\" for g in GRANULARITY_ORDER]\n",
    "    pivot[\"pattern\"] = pivot[sign_cols].apply(\n",
    "        lambda row: \"\".join(row.values.astype(str)),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Definir count como soma do support_abs\n",
    "    support_cols = [f\"{g}_support\" for g in GRANULARITY_ORDER]\n",
    "    pivot[\"count\"] = pivot[support_cols].sum(axis=1)\n",
    "\n",
    "    # Tabela final\n",
    "    table = (\n",
    "        pivot[[\"author\", \"with_author\", \"tradition\", \"pattern\", \"count\"]]\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Uso\n",
    "# --------------------------------------------------\n",
    "\n",
    "pattern_table = build_pattern_table_from_authors_df(authors_df)\n",
    "\n",
    "pattern_table.to_csv(\"../data/processed/pattern_table.csv\")\n",
    "\n",
    "pattern_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "granularity_order = [\n",
    "    \"sentence_id\",\n",
    "    \"paragraph_id\",\n",
    "    \"section_id\",\n",
    "    \"paper_id\"\n",
    "]\n",
    "\n",
    "df = authors_df.copy()\n",
    "\n",
    "# 1. Sinal do lift\n",
    "if \"lift_relation\" not in df.columns:\n",
    "    df[\"lift_relation\"] = df[\"lift\"].apply(lambda x: \"+\" if x >= 1 else \"-\")\n",
    "\n",
    "# 2. Ordem das granularidades\n",
    "df[\"granularity\"] = pd.Categorical(\n",
    "    df[\"granularity\"],\n",
    "    categories=granularity_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# 3. Uma linha por author √ó tradition\n",
    "author_patterns = (\n",
    "    df\n",
    "    .pivot_table(\n",
    "        index=[\"author\", \"tradition\"],\n",
    "        columns=\"granularity\",\n",
    "        values=\"lift_relation\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    "    .reindex(columns=granularity_order)\n",
    ")\n",
    "\n",
    "# 4. Apenas patterns completos\n",
    "author_patterns = author_patterns.dropna()\n",
    "\n",
    "# 5. Pattern multigranular\n",
    "author_patterns[\"pattern\"] = author_patterns.apply(\n",
    "    lambda row: \" \".join(row.values),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "author_patterns = author_patterns.reset_index()\n",
    "\n",
    "# üîπ Total de autores por tradition\n",
    "tradition_totals = (\n",
    "    author_patterns\n",
    "    .groupby(\"tradition\")[\"author\"]\n",
    "    .nunique()\n",
    "    .rename(\"total_authors\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 6. Contagem por tradition √ó pattern\n",
    "pattern_by_tradition = (\n",
    "    author_patterns\n",
    "    .groupby([\"tradition\", \"pattern\"])\n",
    "    .size()\n",
    "    .rename(\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 7. Junta total e calcula propor√ß√£o correta\n",
    "pattern_by_tradition = pattern_by_tradition.merge(\n",
    "    tradition_totals,\n",
    "    on=\"tradition\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "pattern_by_tradition[\"proportion\"] = (\n",
    "    pattern_by_tradition[\"count\"] /\n",
    "    pattern_by_tradition[\"total_authors\"]\n",
    ")\n",
    "\n",
    "# 8. Ordena√ß√£o para inspe√ß√£o\n",
    "pattern_by_tradition.sort_values(\n",
    "    [\"tradition\", \"proportion\", \"pattern\"],\n",
    "    ascending=[True, False, True]\n",
    ").head(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
