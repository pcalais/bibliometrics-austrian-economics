{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEscreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e criar um pandas df em que cada registro tem a coluna paper_id, que é um número sequencial.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_year(citation):\n",
    "    match = re.search(r'\\b(\\d{4})\\b', citation)\n",
    "    return (int(match.group(1)), None) if match else (None, None)\n",
    "\n",
    "\n",
    "def extract_year_and_page(citation):\n",
    "\n",
    "    if citation is None:\n",
    "        return (None, None)\n",
    "\n",
    "    # Use a regular expression to extract the year and page\n",
    "    match = re.search(\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?)[:\\s,]*pp?\\.\\s*(\\d+)(?:-\\d+)?|\"  # Match for \"pp.\" or \"p.\" with year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?):\\s*(\\d+)|\"                     # Match for \":\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*(\\d+)-\\d+|\"                # Match for page range without \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*(\\d+)(?:-\\d+)?|\"           # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?),?\\s*p\\.\\s*(\\d+)|\"              # Match for \"p.\" without explicit parentheses\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]* )?(\\d{4}[a-z]?)\\s*:\\s*(\\d+)|\"                  # Match for \": Page\" format\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*)pp?\\.\\s*(\\d+)|\"                                # Match for \"pp.\" without year\n",
    "        r\"(?:\\b|[^\\(])(?:[^,]*, )?(\\d{4}[a-z]?),\\s*chap\\.\\s*(\\d+)\",           # Match for \"chap.\" format\n",
    "        citation\n",
    "    )\n",
    "    if match:\n",
    "        if match.group(1):  # Match for \"pp.\" or \"p.\" with year\n",
    "            year = match.group(1)\n",
    "            page = int(match.group(2))\n",
    "        elif match.group(3):  # Match for \":\" format\n",
    "            year = match.group(3)\n",
    "            page = int(match.group(4))\n",
    "        elif match.group(5):  # Match for single \"p.\" with year\n",
    "            year = match.group(5)\n",
    "            page = int(match.group(6))\n",
    "        elif match.group(7):  # Match for range without \"pp.\" or \"p.\"\n",
    "            year = match.group(7)\n",
    "            page = int(match.group(8))\n",
    "        elif match.group(9):  # Match for year and page without explicit \"pp.\" or \"p.\"\n",
    "            year = match.group(9)\n",
    "            page = int(match.group(10))\n",
    "        elif match.group(11):  # Match for \"p.\" without year and page\n",
    "            year = match.group(11)\n",
    "            page = int(match.group(12))\n",
    "        elif match.group(13):  # Match for \": Page\" format\n",
    "            year = match.group(13)\n",
    "            page = int(match.group(14))\n",
    "        elif match.group(15):  # Match for \"pp.\" without year\n",
    "            year = None\n",
    "            page = int(match.group(15))\n",
    "        elif match.group(16):  # Match for \"chap.\" format\n",
    "            year = match.group(16)\n",
    "            page = int(match.group(17))\n",
    "        \n",
    "        # Strip the letter suffix from the year before returning (if present)\n",
    "        if year:\n",
    "            year = int(re.match(r'\\d{4}', year).group())\n",
    "\n",
    "        return year, page\n",
    "    else:\n",
    "        return extract_year(citation)  # Return None if the format doesn't match\n",
    "    \n",
    "\n",
    "# Test the function\n",
    "assert extract_year_and_page(\"Mises (1949, p.258)\") == (1949, 258)\n",
    "assert extract_year_and_page(\"(Mises, 1996, pp. 538-86)\") == (1996, 538)\n",
    "assert extract_year_and_page(\"(von Mises, 1963, p.254)\") == (1963, 254)\n",
    "assert extract_year_and_page(\"(Mises, 1920, 121-122)\") == (1920, 121)\n",
    "assert extract_year_and_page(\"(Mises 1949, 236-237)\") == (1949, 236)\n",
    "assert extract_year_and_page(\"(Mises 1920, 109)\") == (1920, 109)\n",
    "assert extract_year_and_page(\"(Mises 1920, p.162)\") == (1920, 162)\n",
    "assert extract_year_and_page(\"(von Mises, 1949: 351)\") == (1949, 351)\n",
    "assert extract_year_and_page(\"(Mises 1966: 493)\") == (1966, 493)\n",
    "assert extract_year_and_page(\"(von Mises 1998, p. 270)\") == (1998, 270)\n",
    "assert extract_year_and_page(\"Mises 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"Mises 1985b, p. 236\") == (1985, 236)\n",
    "assert extract_year_and_page(\"Mises 1957b, 372\") == (1957, 372)\n",
    "assert extract_year_and_page(\"Mises, pp. 105-6;\") == (None, 105)\n",
    "assert extract_year_and_page(\"(Mises, 1949, p. 3)\") == (1949, 3)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949, pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(L Von Mises 1949 , pp. 393)\") == (1949, 393)\n",
    "assert extract_year_and_page(\"(C Berg 2022)\") == (2022, None)\n",
    "assert extract_year_and_page(\"Hayek (1976:71)\") == (1976, 71)\n",
    "assert extract_year_and_page(\"According to Mises ([1949] 1998: 116)\") == (1998, 116)\n",
    "\n",
    "\n",
    "assert extract_year_and_page(None) == (None, None)\n",
    "assert extract_year_and_page(\"[and]\") == (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnson\n",
      "Jouvenel\n",
      "Keen\n",
      "Menger\n",
      "Mises\n",
      "Hayek\n",
      "De Broglie\n",
      "Van Der Waals\n",
      "Mcgrath\n",
      "Allen\n",
      "Folta\n",
      "Boettke\n",
      "Floss\n",
      "Floss\n",
      "Mises\n",
      "Mises\n",
      "Mises\n",
      "Mises\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_author(ref):\n",
    "    \"\"\"\n",
    "    Extracts the author's full name from a reference string, including multi-word names,\n",
    "    names with suffixes like 'et al.', and cases where the name appears before a closing parenthesis.\n",
    "    \n",
    "    Args:\n",
    "        ref (str): A reference string (e.g., \"McGrath et al., 2004: 96\" or \"Allen 2005)\").\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted author's full name with proper capitalization, or None if no name is found.\n",
    "    \"\"\"\n",
    "    if ref == None:\n",
    "        return None\n",
    "\n",
    "    # Regular expression to capture names, including edge cases, and possessive form ('s)\n",
    "    match = re.search(r\"([A-Za-z][A-Za-z\\s\\.]+?)(?=\\s\\d{4}|\\s\\[|\\s\\(|,|:|\\))\", ref)\n",
    "    if match:\n",
    "        # Capitalize each word, handling special cases for prefixes and suffixes\n",
    "        name = match.group(1).strip()\n",
    "        \n",
    "        # Handle multi-word names and ensure proper capitalization, ignoring 'et al.'\n",
    "        temp = \" \".join(word.capitalize() if word.lower() not in {\"et\", \"al.\"} else word for word in name.split()) \\\n",
    "                  .replace(\"Von Mises\", \"Mises\") \\\n",
    "                  .replace(\"L V Mises\", \"Mises\") \\\n",
    "                  .replace(\"L Mises\", \"Mises\") \\\n",
    "                  .replace(\"Von Hayek\", \"Hayek\") \\\n",
    "                  .replace(\"F A Hayek\", \"Hayek\") \\\n",
    "                  .replace(\"K Marx\", \"Marx\") \\\n",
    "                  .replace(\" et al.\", \"\") \n",
    "        \n",
    "        temp = temp.split(\" And\")[0] if \" And\" in temp else temp\n",
    "        return temp\n",
    "\n",
    "    \n",
    "    # Special case for single-word names like Folta (1998)\n",
    "    match_single_word = re.search(r\"([A-Za-z]+(?:'s)?)(?=\\s\\d{4}|\\s\\(|:|\\))\", ref)\n",
    "    if match_single_word:\n",
    "        # Remove possessive 's' if present\n",
    "        name = match_single_word.group(1).replace(\"'s\", \"\")\n",
    "        return name.capitalize()\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test cases\n",
    "print(extract_author(\"Johnson, 1999;\"))             # Output: Johnson\n",
    "print(extract_author(\"Jouvenel (1961)\"))            # Output: Jouvenel\n",
    "print(extract_author(\"Keen 2011\"))                  # Output: Keen\n",
    "print(extract_author(\"(Menger, [1981])\"))           # Output: Menger\n",
    "print(extract_author(\"von Mises (1949)\"))           # Output: Von Mises\n",
    "print(extract_author(\"Von Hayek (1949)\"))           # Output: Von Mises\n",
    "print(extract_author(\"de Broglie (1924)\"))          # Output: De Broglie\n",
    "print(extract_author(\"Van der Waals (1873)\"))       # Output: Van Der Waals\n",
    "print(extract_author(\"(McGrath et al., 2004: 96)\")) # Output: McGrath Et Al.\n",
    "print(extract_author(\"Allen 2005)\"))                # Output: Allen\n",
    "print(extract_author(\"Folta's (1998)\"))             # Output: Folta\n",
    "print(extract_author(\"Boettke et al. (1998)\"))\n",
    "print(extract_author(\"Floss and Klein (1998)\"))\n",
    "print(extract_author(\"Floss And Klein (1998)\"))\n",
    "print(extract_author(\"(Von Mises 1949 )\"))\n",
    "print(extract_author(\"(L V Mises 1949 )\"))\n",
    "print(extract_author(\"(L Mises 1998 )\"))\n",
    "print(extract_author(\"(L Von Mises 1998 )\"))\n",
    "\n",
    "assert extract_author(None) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Gere código python que cria uma classe Reference que tem atributos: raw, context, sentence_seq_number, sentence_id, author, page, year. \n",
    "raw, context, e sentence_id são passados pelo construtor.\n",
    "page e year são obtidos a partir da chamada à extract_year_and_page(raw), que retorna uma tupla (year, page).\n",
    "author é obtido a partir da chamada a extract_author(raw).\n",
    "'''\n",
    "\n",
    "class Reference:\n",
    "    def __init__(self, raw, context, sentence_seq_number, sentence_id):\n",
    "        self.raw = raw\n",
    "        self.context = context\n",
    "        self.sentence_seq_number = sentence_seq_number\n",
    "        self.sentence_id = sentence_id\n",
    "\n",
    "        self.year, self.page = extract_year_and_page(raw)\n",
    "        self.author = extract_author(raw)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Reference(raw={self.raw!r}, context={self.context!r}, \"\n",
    "                f\"sentence_id={self.sentence_id!r}, year={self.year!r}, page={self.page!r})\")\n",
    "\n",
    "\n",
    "\n",
    "ref = Reference(\"(L Von Mises 1949 , pp. 393)\", \"\",  3, \"123\")\n",
    "assert ref.year == 1949\n",
    "assert ref.page == 393\n",
    "assert ref.sentence_seq_number == 3\n",
    "assert ref.author == \"Mises\"\n",
    "\n",
    "\n",
    "ref = Reference(None, None, None, None)\n",
    "assert ref.year == None\n",
    "assert ref.page == None\n",
    "assert ref.sentence_seq_number == None\n",
    "assert ref.author == None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "\n",
    "Write a function parse_tei(tei_filepath) that opens the TEI XML file and counts the number of biblStruct entries. \n",
    "Also, count the number of <s></s> entries. \n",
    "Return four values:  \n",
    "1. The paper title, available in teiHeader / fileDesc / titleStmt / title.\n",
    "2. the number of s entries\n",
    "3. the number of biblStruct entries\n",
    "4. a list of Reference objects.  \n",
    "\n",
    "Each reference object has a field raw, a field sentence_seq_number, a field sentence_id and a field context. \n",
    "\n",
    "Raw should be filled with the text inside the ref tag; context should be filled with the text on the parent <s> tag. \n",
    "sentence_seq should be filled with the sequential count of the <s> in the XML file, e.g, sentence_seq = 10 if s is the 10th sentence in the file.\n",
    "sentence_id should be filled with the value of the property \"xml:id\" from the parent <s> tag.\n",
    "\n",
    "'''\n",
    "\n",
    "from lxml import etree\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def parse_tei(tei_filepath: str) -> Tuple[str, int, int, List[Reference]]:\n",
    "    # Parse the XML\n",
    "    parser = etree.XMLParser(ns_clean=True)\n",
    "    tree = etree.parse(tei_filepath, parser)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # TEI namespace (if any)\n",
    "    nsmap = root.nsmap.copy()\n",
    "    nsmap['tei'] = nsmap.get(None, 'http://www.tei-c.org/ns/1.0')\n",
    "\n",
    "    # 1. Paper title\n",
    "    title_xpath = './/tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title'\n",
    "    title_elem = root.find(title_xpath, namespaces=nsmap)\n",
    "    title = title_elem.text.strip() if title_elem is not None and title_elem.text is not None else \"Unknown Title\"\n",
    "\n",
    "    # 2. Count number of <s> entries\n",
    "    s_xpath = './/tei:s'\n",
    "    s_elems = root.findall(s_xpath, namespaces=nsmap)\n",
    "    num_s = len(s_elems)\n",
    "\n",
    "    # 3. Count number of <biblStruct> entries\n",
    "    bibl_xpath = './/tei:biblStruct'\n",
    "    bibl_elems = root.findall(bibl_xpath, namespaces=nsmap)\n",
    "    num_bibl = len(bibl_elems)\n",
    "\n",
    "    # 4. References\n",
    "    references = []\n",
    "    for idx, s in enumerate(s_elems, start=1):\n",
    "        sentence_id = s.get('{http://www.w3.org/XML/1998/namespace}id')\n",
    "        context_text = ''.join(s.itertext()).strip()\n",
    "\n",
    "        for ref in s.findall('.//tei:ref', namespaces=nsmap):\n",
    "            ref_text = ''.join(ref.itertext()).strip()\n",
    "            references.append(Reference(\n",
    "                raw=ref_text,\n",
    "                sentence_seq_number=idx,\n",
    "                sentence_id=sentence_id,\n",
    "                context=context_text\n",
    "            ))\n",
    "\n",
    "    return title, num_s, num_bibl, references\n",
    "\n",
    "\n",
    "paper_path = \"../data/teis/from-scopus/A-Historical-Intervention-in-the-Opportunity-Wars-Forgotten-Scholarship-the-DiscoveryCreation-Disruption-and-Moving-Forward-by-Looking-Backward_2023_SAGE-Publications-Ltd.pdf.grobid.tei.xml\"\n",
    "title, sentence_count, reference_count, refs = parse_tei(paper_path) \n",
    "\n",
    "assert sentence_count == 283\n",
    "assert reference_count == 106\n",
    "assert len(refs) == 222\n",
    "assert title == \"A Historical Intervention in the \\\"Opportunity Wars\\\": Forgotten Scholarship, the Discovery/Creation Disruption, and Moving Forward by Looking Backward\"\n",
    "assert refs[0].sentence_id == '_efadFU6'\n",
    "assert refs[0].sentence_seq_number == 7\n",
    "\n",
    "paper_path = \"../data/teis/from-scopus/A-heterodox-kzgazdasgtan-helyzete-a-gazdasgtudomnyban_2021_State-Audit-Office-of-Hungary.pdf.grobid.tei.xml\"\n",
    "title, sentence_count, reference_count, refs = parse_tei(paper_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prompt:\n",
    "Escreva código python que escreve uma função read_tei_papers(path) que lê o nome de todos os arquivos XML de path e cria dois dataframes.\n",
    "Um pandas df chamado \"papers_df\" em que cada registro tem a coluna paper_id, que é um número sequencial, além das colunas title, filename, sentence_count, reference_count.\n",
    "Para cada arquivo, invoque parse_tei(tei_filepath), que retorna sentence_count, reference_count e refs.  \n",
    "Adicione sentence_count e reference_count no papers_df.  \n",
    "Add a try-catch loop that catches exceptions in XML Parsing.\n",
    "Ao outro df, chamado refs_df, adicione todos os refs. Um ref é um objeto Reference que tem os campos raw, context, sentence_id, sentence_seq_number e page.\n",
    "Cada campo deve ser uma coluna em refs_df.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from xml.etree.ElementTree import ParseError\n",
    "\n",
    "\n",
    "def read_tei_papers(path: str):\n",
    "    papers = []\n",
    "    refs = []\n",
    "    paper_id = 0\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            tei_filepath = os.path.join(path, filename)\n",
    "            try:\n",
    "                title, sentence_count, reference_count, ref_list = parse_tei(tei_filepath)\n",
    "\n",
    "                # Adiciona entrada ao papers_df\n",
    "                papers.append({\n",
    "                    \"paper_id\": paper_id,\n",
    "                    \"title\": title,\n",
    "                    \"filename\": filename,\n",
    "                    \"sentence_count\": sentence_count,\n",
    "                    \"reference_count\": reference_count\n",
    "                })\n",
    "\n",
    "                # Adiciona entradas ao refs_df\n",
    "                for ref in ref_list:\n",
    "                    refs.append({\n",
    "                        \"paper_id\": paper_id,\n",
    "                        \"raw\": ref.raw,\n",
    "                        \"context\": ref.context,\n",
    "                        \"sentence_id\": ref.sentence_id,\n",
    "                        \"sentence_seq_number\": ref.sentence_seq_number,\n",
    "                        \"author\": ref.author,\n",
    "                        \"page\": ref.page,\n",
    "                        \"year\": ref.year\n",
    "                    })\n",
    "\n",
    "                paper_id += 1\n",
    "\n",
    "            except ParseError as e:\n",
    "                print(f\"Erro ao processar {filename}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro desconhecido em {filename}: {e}\")\n",
    "\n",
    "    # Cria os DataFrames\n",
    "    papers_df = pd.DataFrame(papers)\n",
    "    refs_df = pd.DataFrame(refs)\n",
    "\n",
    "    return papers_df, refs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro desconhecido em Property-is-only-another-name-for-decentralized-creation-of-knowledge_2019_Springer-New-York-LLC-barbarabbertramgskcom.pdf.grobid.tei.xml: Document is empty, line 1, column 1 (../data/teis/from-scopus/Property-is-only-another-name-for-decentralized-creation-of-knowledge_2019_Springer-New-York-LLC-barbarabbertramgskcom.pdf.grobid.tei.xml, line 1)\n"
     ]
    }
   ],
   "source": [
    "papers_df, refs_df = read_tei_papers(\"../data/teis/from-scopus\")\n",
    "\n",
    "papers_df.sort_values(by='reference_count', ascending=False)\n",
    "\n",
    "papers_df.to_csv(\"../data/papers.csv\")\n",
    "refs_df.to_csv(\"../data/refs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
